{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symspell Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and SymSpell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy.symspellpy import SymSpell\n",
    "import spacy\n",
    "from nltk import word_tokenize\n",
    "nlp = spacy.load(\"en_core_web_sm\") # $ python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "symspell = SymSpell(3, 7) # edit_distance = 3, prefix_length = 7\n",
    "\n",
    "# load custom dictionary (increased frequency for words that often appear in documents relating to school shootings)\n",
    "if not symspell.load_dictionary('/Users/elisa/OneDrive/Wesley_mock/spellcheck/frequency_dictionary_en_82_765.txt', term_index=0, count_index=1):\n",
    "    print(\"Cannot find dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell Checking Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_misspelled(words, proper_nouns): # return list of misspelled words from string input\n",
    "    misspelled = []\n",
    "    for i in words:\n",
    "        clean_i = ''.join(spellclean(i.lower())) # removes special characters\n",
    "        if not clean_i.isspace() and clean_i != '' and i.lower() not in proper_nouns \\\n",
    "          and i not in misspelled and (len(symspell.lookup(clean_i, verbosity = 0)) == 0 \\\n",
    "          or symspell.lookup(clean_i, verbosity = 0)[0].term != clean_i):\n",
    "            misspelled.append(i) # deems word misspelled if word is not in the dictionary, is not a proper noun\n",
    "    return misspelled\n",
    "\n",
    "def spellclean(text): # removes parts of text that prevent spellchecking\n",
    "    text = re.sub(r'\\bhttps?:\\/\\/[^\\s]+', '', text)\n",
    "    text = re.sub(r'\\bwww\\.[^\\s]+', '', text)\n",
    "    text = re.sub(r'\\w*\\.com\\b', '', text)\n",
    "    text = re.sub(r'\\w*\\.org\\b', '', text)\n",
    "    text = re.sub(r'\\w*\\.net\\b', '', text)\n",
    "    text = re.sub('\\'s', '', text)\n",
    "    text = re.sub('_', '', text)\n",
    "    text = re.sub('\\d+', '', text)\n",
    "    text = re.sub('\\W+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def get_proper_nouns(text): # returns list of proper nouns (lowercased for consitency)\n",
    "    tagged_output, final_nnps = [], []\n",
    "    tagged_text = nlp(text)\n",
    "    for word in tagged_text:\n",
    "        tagged_output.append((str(word), str(word.tag_)))\n",
    "    nnps = [word for (word, tag) in tagged_output if tag == 'NNP']\n",
    "    [final_nnps.append(i.lower()) for i in nnps if i.lower() not in final_nnps]\n",
    "    return final_nnps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Spell Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symspell_check(text, threshold = 0.02): # returns dictionary of misspelled words and their suggested corrections\n",
    "    text = re.sub('-', ' ', text)\n",
    "    text = re.sub('/', ' ', text)\n",
    "    text = text.replace(r'+', ' ')\n",
    "    proper_nouns = get_proper_nouns(text)\n",
    "    words = word_tokenize(text)\n",
    "    to_return = {}\n",
    "    misspelled = find_misspelled(words, proper_nouns)\n",
    "    if len(misspelled) == 0:\n",
    "        print('No misspelled words have been detected.')\n",
    "        return False\n",
    "    elif len(misspelled)/len(word_tokenize(text)) < threshold:\n",
    "        print('Spell checking not recommended. Your text only contains ' + \n",
    "             str((len(misspelled)/len(word_tokenize(text)))*100) + \n",
    "             '% misspelled words, which is under the ' + str(threshold*100) + '% theshold')\n",
    "        return False\n",
    "    for word in misspelled:\n",
    "        clean_word = ''.join(spellclean(word.lower()))\n",
    "        suggestions = symspell.lookup_compound(clean_word, 3) # find suggestion for misspelled word (edit distance 3)\n",
    "        to_return[word] = suggestions[0].term\n",
    "    return to_return\n",
    "\n",
    "def sub_symspell(text, verbose = False, threshold = 0.02): \n",
    "    suggestions = symspell_check(text, threshold)\n",
    "    if suggestions == False: return text\n",
    "    if verbose: print('Percent of words misspelled: ' + str((len(suggestions)/len(word_tokenize(text))) if isinstance(suggestions, dict) else 0))\n",
    "    if isinstance(suggestions, dict):\n",
    "        for i in suggestions:\n",
    "            text = re.sub(r'([^A-Za-z]{1})' + i + r'([^A-Za-z]{1})', r'\\1' + suggestions[i] + r'\\2', text)\n",
    "            text = re.sub(r'([^A-Za-z]{1})' + i + r'$', r'\\1' + suggestions[i] , text)\n",
    "            text = re.sub(r'^' +i + r'([^A-Za-z]{1})', suggestions[i] + r'\\1', text)\n",
    "            if verbose: print('Misspelled word: ' + i + ' | Suggestion: ' + suggestions[i])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
